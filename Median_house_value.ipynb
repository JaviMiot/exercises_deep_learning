{"cells":[{"cell_type":"markdown","metadata":{"id":"x0uJW5xqqqlm"},"source":["# Machine learning program \"Median House Value\"\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":414,"status":"ok","timestamp":1698054675770,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"V4Dwpm86q2jO","outputId":"e9eeb894-febf-4c3a-9196-594daba05b4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tensorflow version: 2.14.0\n"]}],"source":["import tensorflow as tf\n","from tensorflow import keras\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import time\n","import numpy as np\n","\n","print(\"Tensorflow version: \"+tf.__version__)"]},{"cell_type":"markdown","metadata":{"id":"zCo-PcwtxCbO"},"source":["## Datasets"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2464,"status":"ok","timestamp":1698054678638,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"-SAQX4N2qqls","outputId":"1303dc32-b6bd-4746-bc37-9d932259f7a7"},"outputs":[],"source":["ATT_FILE =   f\"MedianHouseValuePreparedCleanAttributes.csv\"\n","LABEL_FILE = f\"MedianHouseValueOneHotEncodedClasses.csv\"\n","\n","attributes = pd.read_csv(ATT_FILE)\n","label =      pd.read_csv(LABEL_FILE)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1698054678639,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"ms5bg-YEvJxr","outputId":"a6231318-fcfd-48b5-d232-86ef272a74b2"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>longitude</th>\n","      <th>latitude</th>\n","      <th>housing_median_age</th>\n","      <th>total_rooms</th>\n","      <th>total_bedrooms</th>\n","      <th>population</th>\n","      <th>households</th>\n","      <th>median_income</th>\n","      <th>ocean_proximity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.217131</td>\n","      <td>-0.693943</td>\n","      <td>0.411765</td>\n","      <td>-0.939264</td>\n","      <td>-0.887337</td>\n","      <td>-0.909246</td>\n","      <td>-0.892781</td>\n","      <td>-0.775851</td>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.693227</td>\n","      <td>0.177471</td>\n","      <td>-0.294118</td>\n","      <td>-0.917951</td>\n","      <td>-0.886716</td>\n","      <td>-0.954483</td>\n","      <td>-0.889492</td>\n","      <td>-0.591592</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.448207</td>\n","      <td>-0.959617</td>\n","      <td>0.372549</td>\n","      <td>-0.830663</td>\n","      <td>-0.800745</td>\n","      <td>-0.893495</td>\n","      <td>-0.795757</td>\n","      <td>-0.558972</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.290837</td>\n","      <td>-0.708820</td>\n","      <td>-0.411765</td>\n","      <td>-0.876291</td>\n","      <td>-0.859094</td>\n","      <td>-0.943160</td>\n","      <td>-0.843776</td>\n","      <td>-0.487055</td>\n","      <td>-1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.400398</td>\n","      <td>0.158342</td>\n","      <td>-0.490196</td>\n","      <td>-0.841854</td>\n","      <td>-0.845748</td>\n","      <td>-0.934135</td>\n","      <td>-0.827660</td>\n","      <td>-0.164687</td>\n","      <td>-0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n","0   0.217131 -0.693943            0.411765    -0.939264       -0.887337   \n","1  -0.693227  0.177471           -0.294118    -0.917951       -0.886716   \n","2   0.448207 -0.959617            0.372549    -0.830663       -0.800745   \n","3   0.290837 -0.708820           -0.411765    -0.876291       -0.859094   \n","4  -0.400398  0.158342           -0.490196    -0.841854       -0.845748   \n","\n","   population  households  median_income  ocean_proximity  \n","0   -0.909246   -0.892781      -0.775851        -1.000000  \n","1   -0.954483   -0.889492      -0.591592         1.000000  \n","2   -0.893495   -0.795757      -0.558972         1.000000  \n","3   -0.943160   -0.843776      -0.487055        -1.000000  \n","4   -0.934135   -0.827660      -0.164687        -0.333333  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["attributes.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1698054678639,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"-5seWhRavWxC","outputId":"e93ca6bb-6e14-4ec0-c378-a6d34bceec6d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Cheap:[15.0, 141.3]</th>\n","      <th>Averaged:[141.4, 230.2]</th>\n","      <th>Expensive:[230.3, 500.0]</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Cheap:[15.0, 141.3]  Averaged:[141.4, 230.2]  Expensive:[230.3, 500.0]\n","0                  1.0                      0.0                       0.0\n","1                  0.0                      0.0                       1.0\n","2                  1.0                      0.0                       0.0\n","3                  0.0                      1.0                       0.0\n","4                  0.0                      0.0                       1.0"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["label.head()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1698054678639,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"xfEOrwcr-ft8","outputId":"667993d7-4ea8-4fd4-92bd-23709ae65fbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training examples:  16342\n","Number of examples for development test:  2043\n"]}],"source":["TRAIN_RATIO = 0.8\n","\n","n_instances = attributes.shape[0]\n","n_train = int(n_instances*TRAIN_RATIO)\n","n_dev = int((n_instances - n_train)/2)\n","\n","x_train = attributes.values[:n_train]\n","t_train = label.values[:n_train]\n","x_dev =   attributes.values[n_train:n_train + n_dev]\n","t_dev =   label.values[n_train:n_train + n_dev]\n","\n","INPUTS =  x_train.shape[1]\n","OUTPUTS = t_train.shape[1]\n","\n","NUM_TRAINING_EXAMPLES = int(round(x_train.shape[0]/1))\n","NUM_DEV_EXAMPLES =      int(round(x_dev.shape[0]/1))\n","\n","print (\"Number of training examples: \", NUM_TRAINING_EXAMPLES)\n","print (\"Number of examples for development test: \", NUM_DEV_EXAMPLES)"]},{"cell_type":"markdown","metadata":{"id":"hisRDds_kfFb"},"source":["## Model\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698054678639,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"9llGmGvkqqmM"},"outputs":[],"source":["n_neurons_per_hidden_layer = [500, 250, 75, 25]\n","learning_rate = 0.1"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698054678639,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"_HC6q86_IzO7"},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-10-24 09:27:14.417422: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:14.424675: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:14.425048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:14.426876: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:14.427408: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:14.427905: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:16.280544: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:16.281314: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:16.281353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n","2023-10-24 09:27:16.281879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n","Your kernel may have been built without NUMA support.\n","2023-10-24 09:27:16.281963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2873 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n"]}],"source":["model = keras.Sequential(name=\"my_model\")\n","\n","model.add(keras.layers.InputLayer(input_shape=(INPUTS,)))\n","for neurons in n_neurons_per_hidden_layer:\n","  model.add(keras.layers.Dense(neurons, activation=\"relu\"))\n","model.add(keras.layers.Dense(OUTPUTS, activation=\"softmax\"))"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698054678640,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"XisSOCL1UDh8"},"outputs":[],"source":["model.compile(loss=tf.keras.losses.categorical_crossentropy,\n","              optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n","              metrics=[\"categorical_accuracy\"])\n"]},{"cell_type":"markdown","metadata":{"id":"oQZsDnk8bCa8"},"source":["## Training"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1698054678640,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"7xiouC6pbG0m"},"outputs":[],"source":["n_epochs = 1000\n","batch_size = 512\n","start_time = time.perf_counter()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":143892,"status":"ok","timestamp":1698054822522,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"2Z79Zz4Owszp"},"outputs":[],"source":["history = model.fit(x_train, t_train,\n","                    batch_size = batch_size,\n","                    epochs=n_epochs,\n","                    verbose = 0,\n","                    validation_data = (x_dev, t_dev))"]},{"cell_type":"markdown","metadata":{"id":"JFjtHnWH8-99"},"source":["## Results"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":470},"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1698054823531,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"ei8jQFBcgqQ1","outputId":"476a1f60-4899-42d0-f3e2-9b611f3b41a6"},"outputs":[],"source":["results = pd.DataFrame(history.history)\n","results.plot(figsize = (8, 5))\n","plt.grid(True)\n","plt.xlabel (\"Epochs\")\n","plt.ylabel (\"Accuracy - Mean Log Loss\")\n","plt.gca().set_ylim(0, 1) # set the vertical range to [0,1]\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1698054823532,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"PWFtUYNKqqmX","outputId":"a322f623-820c-4bb4-aed4-9edea0ba5fba"},"outputs":[],"source":["print (\"Error (training): \",\n","       round((1 - results.categorical_accuracy.values[-1:][0])*100, 1), \"%\")\n","print (\"Error (development test): \",\n","       round((1 - results.val_categorical_accuracy.values[-1:][0])*100, 1), \"%\")\n","print (\"Time: \",\n","       round((time.perf_counter() - start_time)),\"seconds\")"]},{"cell_type":"markdown","metadata":{"id":"2pHAB2nTxMAj"},"source":["## **Exercises**"]},{"cell_type":"markdown","metadata":{"id":"r37fPgT3xSiG"},"source":["### **Exercise 1.**\n","Performance evaluation  Determine the following values: train error, test error (using dev set), bias, variance and training time. Repeat the execution at least three times. Consider 5% as Bayesian error (human error)."]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1698054823532,"user":{"displayName":"Javier Manobanda","userId":"15828105867417165470"},"user_tz":-120},"id":"6tbqPQk-xObX","outputId":"648fe0ce-cbb0-4042-e287-eaf7d801efb4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>train error</th>\n","      <th>test error</th>\n","      <th>bias</th>\n","      <th>variance</th>\n","      <th>training time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>17.7</td>\n","      <td>20.2</td>\n","      <td>12.7</td>\n","      <td>2.5</td>\n","      <td>203</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>9.5</td>\n","      <td>21.0</td>\n","      <td>4.5</td>\n","      <td>11.5</td>\n","      <td>1660</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.5</td>\n","      <td>20.9</td>\n","      <td>-2.5</td>\n","      <td>18.4</td>\n","      <td>155</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   train error  test error  bias  variance  training time (s)\n","0         17.7        20.2  12.7       2.5                203\n","1          9.5        21.0   4.5      11.5               1660\n","2          2.5        20.9  -2.5      18.4                155"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["human_error = 5\n","train_errors = [17.7, 9.5, 2.5]\n","test_errors = [20.2, 21.0, 20.9]\n","training_times = [203, 1660, 155]\n","bias = [ e - human_error for e in train_errors]\n","variance = [e - train_errors[i] for i, e in enumerate(test_errors)]\n","\n","data = {\n","    \"train error\" : train_errors,\n","    \"test error\": test_errors,\n","    \"bias\":bias,\n","    \"variance\":variance,\n","    'training time (s)': training_times\n","    }\n","\n","values = pd.DataFrame(data)\n","values"]},{"cell_type":"markdown","metadata":{"id":"GcNlKIYO2QDQ"},"source":["### **Exercise 2:**\n","Changing basic hyperparameters  Change hyperparameters related to: batch size, number of layers, and number of neurons. Estimate train error, test error, bias, variance and training time. Consider 5% as Bayesian error (human error)."]},{"cell_type":"markdown","metadata":{"id":"3v-ELRyu3Q8w"},"source":["#### **Change the batch size**"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"QtFNAgck5cjx"},"outputs":[],"source":["n_epochs = 1000\n","batch_sizes = [16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192, 16384]\n","\n","\n","def calc_measures(history, start_time):\n","  results = pd.DataFrame(history.history)\n","  error_trainig =  round((1 - results.categorical_accuracy.values[-1:][0])*100, 1)\n","  error_test = round((1 - results.val_categorical_accuracy.values[-1:][0])*100, 1)\n","  total_time = round((time.perf_counter() - start_time))\n","  print (\"Error (training): \",error_trainig, \"%\")\n","  print (\"Error (development test): \",error_test, \"%\")\n","  print (\"Time: \",time,\"seconds\")\n","  return error_trainig, error_test, total_time\n","\n","train_errors = []\n","test_errors = []\n","training_times = []\n","\n","for batch_size in batch_sizes:\n","  start_time = time.perf_counter()\n","\n","  history = model.fit(x_train, t_train,\n","                      batch_size = batch_size,\n","                      epochs=n_epochs,\n","                      verbose = 0,\n","                      validation_data = (x_dev, t_dev))\n","\n","  error_training, error_test, total_time = calc_measures(history, start_time)\n","  train_errors.append(error_training)\n","  test_errors.append(error_test)\n","  training_times.append(total_time)\n","\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"iKYiO1Vc5aSX"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>batch size</th>\n","      <th>N</th>\n","      <th>train error</th>\n","      <th>test error</th>\n","      <th>bias</th>\n","      <th>variance</th>\n","      <th>training time (s)</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>16342</td>\n","      <td>1000.0</td>\n","      <td>28.5</td>\n","      <td>28.8</td>\n","      <td>23.5</td>\n","      <td>0.3</td>\n","      <td>125</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   batch size       N  train error  test error  bias  variance  \\\n","0       16342  1000.0         28.5        28.8  23.5       0.3   \n","\n","   training time (s)  \n","0                125  "]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["bias = [ e - human_error for e in train_errors]\n","variance = [e - train_errors[i] for i, e in enumerate(test_errors)]\n","iterations = [ (n_train/batch_size) *n_epochs for batch_size in batch_sizes]\n","data = {\n","    \"batch size\": batch_sizes,\n","    \"N\":iterations,\n","    \"train error\" : train_errors,\n","    \"test error\": test_errors,\n","    \"bias\":bias,\n","    \"variance\":variance,\n","    'training time (s)': training_times\n","    }\n","\n","values = pd.DataFrame(data)\n","values"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
